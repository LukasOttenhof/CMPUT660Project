{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTopic Analysis & Sentiment\n",
    "\n",
    "This notebook uses **BERTopic** (Transformer-based topic modeling) instead of LDA. \n",
    "It requires installing the `bertopic` library.\n",
    "\n",
    "**Note:** BERTopic runs best on a GPU. If running locally on CPU, it may be slower than LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bertopic\n",
      "  Obtaining dependency information for bertopic from https://files.pythonhosted.org/packages/98/05/2d6b305391efff89c2b4cf19cf847f971ca163eb5c149d0d2ffac0a9c7ed/bertopic-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: nltk in /Users/lukas./anaconda3/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in /Users/lukas./anaconda3/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /Users/lukas./anaconda3/lib/python3.11/site-packages (18.0.0)\n",
      "Requirement already satisfied: seaborn in /Users/lukas./anaconda3/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib in /Users/lukas./anaconda3/lib/python3.11/site-packages (3.7.2)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Obtaining dependency information for hdbscan>=0.8.29 from https://files.pythonhosted.org/packages/26/6b/88b8c8023c0c0b27589ad83c82084a1b751917a3e09bdf7fcacf7e6bd523/hdbscan-0.8.40-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading hdbscan-0.8.40-cp311-cp311-macosx_10_9_universal2.whl.metadata (15 kB)\n",
      "Collecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Obtaining dependency information for umap-learn>=0.5.0 from https://files.pythonhosted.org/packages/6b/b1/c24deeda9baf1fd491aaad941ed89e0fed6c583a117fd7b79e0a33a1e6c0/umap_learn-0.5.9.post2-py3-none-any.whl.metadata\n",
      "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from bertopic) (1.26.4)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from bertopic) (5.9.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from bertopic) (1.3.0)\n",
      "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
      "  Obtaining dependency information for sentence-transformers>=0.4.1 from https://files.pythonhosted.org/packages/bb/a6/a607a737dc1a00b7afe267b9bfde101b8cee2529e197e57471d23137d4e5/sentence_transformers-5.1.2-py3-none-any.whl.metadata\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from bertopic) (4.67.0)\n",
      "Requirement already satisfied: llvmlite>0.36.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from bertopic) (0.40.0)\n",
      "Requirement already satisfied: click in /Users/lukas./anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/lukas./anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from hdbscan>=0.8.29->bertopic) (1.11.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from plotly>=4.7.0->bertopic) (8.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0->bertopic) (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.47.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.26.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.4.1->bertopic) (4.15.0)\n",
      "Collecting scikit-learn>=1.0 (from bertopic)\n",
      "  Obtaining dependency information for scikit-learn>=1.0 from https://files.pythonhosted.org/packages/18/d6/ba863a4171ac9d7314c4d3fc251f015704a2caeee41ced89f321c049ed83/scikit_learn-1.7.2-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from umap-learn>=0.5.0->bertopic) (0.57.1)\n",
      "Collecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Obtaining dependency information for pynndescent>=0.5 from https://files.pythonhosted.org/packages/d2/53/d23a97e0a2c690d40b165d1062e2c4ccc796be458a1ce59f6ba030434663/pynndescent-0.5.13-py3-none-any.whl.metadata\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0->bertopic)\n",
      "  Obtaining dependency information for threadpoolctl>=3.1.0 from https://files.pythonhosted.org/packages/32/d5/f9a850d79b0851d1d4ef6456097579a9005b31fea68726a4ae5f2d82ddd9/threadpoolctl-3.6.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /Users/lukas./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0)\n",
      "Requirement already satisfied: requests in /Users/lukas./anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.5)\n",
      "Collecting numpy>=1.20.0 (from bertopic)\n",
      "  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/c0/bc/77635c657a3668cf652806210b8662e1aff84b818a55ba88257abf6637a8/numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: networkx in /Users/lukas./anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lukas./anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2025.10.5)\n",
      "Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hdbscan-0.8.40-cp311-cp311-macosx_10_9_universal2.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.0/488.0 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.7.2-cp311-cp311-macosx_12_0_arm64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, scikit-learn, pynndescent, hdbscan, umap-learn, sentence-transformers, bertopic\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 2.2.0\n",
      "    Uninstalling threadpoolctl-2.2.0:\n",
      "      Successfully uninstalled threadpoolctl-2.2.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bertopic-0.17.3 hdbscan-0.8.40 numpy-1.24.4 pynndescent-0.5.13 scikit-learn-1.7.2 sentence-transformers-5.1.2 threadpoolctl-3.6.0 umap-learn-0.5.9.post2\n"
     ]
    }
   ],
   "source": [
    "# # Install necessary packages if not present\n",
    "# !pip install bertopic nltk pandas pyarrow seaborn matplotlib\n",
    "!pip install validate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'validate_data' from 'sklearn.utils.validation' (/Users/lukas./anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bertopic/_bertopic.py:41\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhdbscan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HDBSCAN\n\u001b[1;32m     43\u001b[0m     HAS_HDBSCAN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hdbscan/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhdbscan_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HDBSCAN, hdbscan\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrobust_single_linkage_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobustSingleLinkage, robust_single_linkage\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/hdbscan/hdbscan_.py:12\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KDTree, BallTree\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Memory\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/__init__.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ball_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BallTree\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VALID_METRICS, VALID_METRICS_SPARSE, sort_graph_by_row_values\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KNeighborsClassifier, RadiusNeighborsClassifier\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/neighbors/_base.py:25\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     check_array,\n\u001b[1;32m     27\u001b[0m     gen_even_slices,\n\u001b[1;32m     28\u001b[0m     get_tags,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, StrOptions, validate_params\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_tags' from 'sklearn.utils' (/Users/lukas./anaconda3/lib/python3.11/site-packages/sklearn/utils/__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Download VADER lexicon\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bertopic/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m      5\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbertopic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBERTopic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/bertopic/_bertopic.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     HAS_HDBSCAN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HDBSCAN \u001b[38;5;28;01mas\u001b[39;00m SK_HDBSCAN\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m normalize\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m sklearn_version\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/cluster/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Popular unsupervised clustering algorithms.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AffinityPropagation, affinity_propagation\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_agglomerative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     AgglomerativeClustering,\n\u001b[1;32m      9\u001b[0m     FeatureAgglomeration,\n\u001b[1;32m     10\u001b[0m     linkage_tree,\n\u001b[1;32m     11\u001b[0m     ward_tree,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bicluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpectralBiclustering, SpectralCoclustering\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_affinity_propagation.py:17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_random_state\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, StrOptions, validate_params\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted, validate_data\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_equal_similarities_and_preferences\u001b[39m(S, preference):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_equal_preferences\u001b[39m():\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'validate_data' from 'sklearn.utils.validation' (/Users/lukas./anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Download VADER lexicon\n",
    "try:\n",
    "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "\n",
    "# ==========================================\n",
    "# ⚙️ CONFIGURATION\n",
    "# ==========================================\n",
    "BASE = Path(\"/Users/lukas./Desktop/CMPUT660Project/inputs/processed\")\n",
    "PLOTS_DIR = BASE.parent.parent / \"outputs\" / \"pokemon\" / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "Standard loading of Parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prep(filename):\n",
    "    fpath = BASE / filename\n",
    "    if not fpath.exists():\n",
    "        return pd.DataFrame()\n",
    "  \n",
    "    df = pd.read_parquet(fpath)\n",
    "\n",
    "    date_col = 'date' if 'date' in df.columns else 'created_at'\n",
    "    if date_col in df.columns:\n",
    "        df['date'] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    if 'text' in df.columns:\n",
    "        df = df[['date', 'text']].dropna()\n",
    "        if \"before\" in filename:\n",
    "            df['period'] = 'Before'\n",
    "        else:\n",
    "            df['period'] = 'After'\n",
    "        return df\n",
    "    return pd.DataFrame()\n",
    "\n",
    "files = [\n",
    "    \"commit_messages_before.parquet\", \"commit_messages_after.parquet\",\n",
    "    \"pr_bodies_before.parquet\", \"pr_bodies_after.parquet\"\n",
    "]\n",
    "\n",
    "dfs = [load_and_prep(f) for f in files]\n",
    "full_df = pd.concat(dfs)\n",
    "full_df = full_df.sort_values(by=\"date\")\n",
    "\n",
    "print(f\"Loaded {len(full_df):,} documents.\")\n",
    "\n",
    "# Filter out very short texts which confuse embeddings\n",
    "full_df = full_df[full_df['text'].str.len() > 10]\n",
    "documents = full_df['text'].astype(str).tolist()\n",
    "periods = full_df['period'].tolist()\n",
    "timestamps = full_df['date'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train BERTopic Model\n",
    "Unlike LDA, BERTopic handles stopwords and tokenization internally via embeddings, so manual preprocessing is less critical (though still helpful)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training BERTopic Model... (This may take a while)\")\n",
    "\n",
    "# min_topic_size: Minimum documents per topic\n",
    "# nr_topics: 'auto' or a specific number (e.g., 20)\n",
    "topic_model = BERTopic(\n",
    "    language=\"english\", \n",
    "    calculate_probabilities=True, \n",
    "    verbose=True,\n",
    "    nr_topics=20, # Reducing to manageable number like LDA\n",
    "    min_topic_size=20\n",
    ")\n",
    "\n",
    "topics, probs = topic_model.fit_transform(documents)\n",
    "\n",
    "# Get Topic Info\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info.head(10))\n",
    "\n",
    "# Create Label Map\n",
    "# BERTopic gives topics names like '0_fix_bug_issue'\n",
    "TOPIC_LABELS = {row['Topic']: row['Name'] for index, row in topic_info.iterrows()}\n",
    "print(\"\\n--- Discovered Topics ---\")\n",
    "for t_id, t_name in list(TOPIC_LABELS.items())[:10]:\n",
    "    print(f\"{t_id}: {t_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "We map the BERTopic assignments to VADER sentiment scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating Sentiment...\")\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sentiment_data = []\n",
    "\n",
    "for i, (doc, topic, period) in enumerate(zip(documents, topics, periods)):\n",
    "    # Topic -1 is \"Outlier\" in BERTopic (noise). We usually skip it.\n",
    "    if topic == -1:\n",
    "        continue\n",
    "        \n",
    "    scores = sid.polarity_scores(doc)\n",
    "    compound = scores['compound']\n",
    "    \n",
    "    # Clean up topic name (remove numbers e.g. \"0_fix_bug\" -> \"fix_bug\")\n",
    "    raw_name = TOPIC_LABELS[topic]\n",
    "    clean_name = \"_\".join(raw_name.split(\"_\")[1:]) \n",
    "    \n",
    "    sentiment_data.append({\n",
    "        \"Topic_ID\": topic,\n",
    "        \"Topic_Name\": clean_name,\n",
    "        \"Period\": period,\n",
    "        \"Sentiment\": compound\n",
    "    })\n",
    "\n",
    "df_sentiment = pd.DataFrame(sentiment_data)\n",
    "\n",
    "# --- Visualization ---\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "ax = sns.barplot(\n",
    "    x=\"Topic_Name\", \n",
    "    y=\"Sentiment\", \n",
    "    hue=\"Period\", \n",
    "    data=df_sentiment, \n",
    "    palette=[\"#E74C3C\", \"#3498DB\"],\n",
    "    errorbar=('ci', 95)\n",
    ")\n",
    "\n",
    "plt.title(\"Sentiment Shifts by BERTopic (Before vs After)\", fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel(\"Average Sentiment\", fontsize=12)\n",
    "plt.xlabel(\"Topic (Top Keywords)\", fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.legend(title=\"Time Period\")\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
