{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "all_pr_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_pull_request.parquet\")\n",
        "all_repo_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_repository.parquet\")\n",
        "all_user_df = pd.read_parquet(\"hf://datasets/hao-li/AIDev/all_user.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0849d156",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Ensure created_at is datetime\n",
        "all_pr_df['created_at'] = pd.to_datetime(all_pr_df['created_at'])\n",
        "\n",
        "# Count agent PRs per repo\n",
        "pr_counts = all_pr_df.groupby('repo_id').size().reset_index(name='agent_pr_count')\n",
        "\n",
        "# Filter for repos with >= 1000 agent PRs\n",
        "large_repos = pr_counts[pr_counts['agent_pr_count'] >= 100]\n",
        "\n",
        "# Get first agent PR date per repo\n",
        "first_pr_dates = all_pr_df.groupby('repo_id')['created_at'].min().reset_index(name='first_pr_date')\n",
        "\n",
        "# Merge counts and first date\n",
        "result = large_repos.merge(first_pr_dates, on='repo_id')\n",
        "\n",
        "# Merge with repo metadata for repo name and URL\n",
        "result = result.merge(all_repo_df, left_on='repo_id', right_on='id')\n",
        "\n",
        "# Select relevant columns\n",
        "result = result[['full_name', 'url', 'agent_pr_count', 'first_pr_date']]\n",
        "\n",
        "# Sort by number of agent PRs descending\n",
        "result = result.sort_values(by='agent_pr_count', ascending=False)\n",
        "\n",
        "# Take top 100 repos\n",
        "\n",
        "\n",
        "# Save to TXT\n",
        "with open(\"top_agent_repos.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for idx, row in result.iterrows():\n",
        "        f.write(f\"{row['full_name']} | {row['url']} | {row['agent_pr_count']} agent PRs | first PR: {row['first_pr_date'].date()}\\n\")\n",
        "\n",
        "print(\"Saved top 100 agent repos to top_agent_repos.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfe7e92",
      "metadata": {},
      "outputs": [],
      "source": [
      "from github import Github, Auth\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "import time\n",
      "\n",
      "# --- CONFIGURATION ---\n",
      "GITHUB_TOKEN = \"\"  \n",
      "INPUT_FILE = \"repos_min1000pr.txt\"\n",
      "OUTPUT_FILE = \"filtered_repos.txt\"\n",
      "MIN_YEARS = 3\n",
      "RATE_LIMIT_DELAY = 0.5  # seconds between API calls\n",
      "\n",
      "# --- Initialize GitHub ---\n",
      "g = Github(auth=Auth.Token(GITHUB_TOKEN))\n",
      "\n",
      "# --- Read TXT file ---\n",
      "repos = []\n",
      "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
      "    for line in f:\n",
      "        parts = line.strip().split(\"|\")\n",
      "        if len(parts) < 4:\n",
      "            continue  # skip malformed lines\n",
      "        full_name = parts[0].strip()\n",
      "        repo_url = parts[1].strip()\n",
      "        try:\n",
      "            agent_pr_count = int(parts[2].strip().split()[0])\n",
      "        except:\n",
      "            agent_pr_count = 0\n",
      "        # Extract date after \"first PR:\"\n",
      "        first_agent_pr_str = parts[3].strip()\n",
      "        if first_agent_pr_str.lower().startswith(\"first pr:\"):\n",
      "            first_agent_pr_str = first_agent_pr_str.split(\":\", 1)[1].strip()\n",
      "        try:\n",
      "            first_agent_pr = datetime.fromisoformat(first_agent_pr_str).replace(tzinfo=pd.Timestamp.utcnow().tz)\n",
      "        except:\n",
      "            first_agent_pr = pd.NaT\n",
      "        repos.append((full_name, repo_url, agent_pr_count, first_agent_pr))\n",
      "\n",
      "df = pd.DataFrame(repos, columns=[\"full_name\", \"repo_url\", \"agent_pr_count\", \"first_agent_pr\"])\n",
      "\n",
      "# --- Fetch GitHub repo creation dates ---\n",
      "creation_dates = []\n",
      "for idx, row in df.iterrows():\n",
      "    try:\n",
      "        repo = g.get_repo(row['full_name'])\n",
      "        creation_dates.append(repo.created_at)  # timezone-aware\n",
      "        time.sleep(RATE_LIMIT_DELAY)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to get {row['full_name']}: {e}\")\n",
      "        creation_dates.append(pd.NaT)\n",
      "\n",
      "df['repo_creation_date'] = creation_dates\n",
      "\n",
      "# --- Filter for >=3 years history ---\n",
      "three_years = pd.Timedelta(days=MIN_YEARS*365)\n",
      "df_filtered = df.dropna(subset=['repo_creation_date', 'first_agent_pr'])\n",
      "df_filtered = df_filtered[df_filtered['first_agent_pr'] - df_filtered['repo_creation_date'] >= three_years]\n",
      "\n",
      "# --- Save filtered repos ---\n",
      "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
      "    for _, row in df_filtered.iterrows():\n",
      "        f.write(\n",
      "            f\"{row['full_name']} | {row['repo_url']} | {row['agent_pr_count']} agent PRs | \"\n",
      "            f\"first agent PR: {row['first_agent_pr'].date()} | repo creation: {row['repo_creation_date'].date()}\\n\"\n",
      "        )\n",
      "\n",
      "print(f\"Filtered repos saved to {OUTPUT_FILE}\")\n"
   ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
